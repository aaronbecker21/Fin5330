{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Chapter 2: Linear Time Series Analysis and Its Applications__\n",
    "\n",
    "<br>\n",
    "\n",
    "Finance 5330: Financial Econometrics <br>\n",
    "Tyler J. Brough <br>\n",
    "First Date: January 19, 2019 <br>\n",
    "Last Date: January 20, 2019 <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "These notes are based on Chapter 2 of the book _Analysis of Financial Time Series 3rd Ed_ by Ruey Tsay. \n",
    "\n",
    "Understanding the simple time series models introduced here will go a long way to better appreciate the more sophisticated financial econometric models of later chapters.\n",
    "\n",
    "<br>\n",
    "\n",
    "Treating an asset return (e.g. log return $r_{t}$ of a stock) as a collection of random variables over time., we have a time series $\\{r_{t}\\}$. The Linear time series models of this chapter are a natural first attemp at modeling such dynamic behavior. \n",
    "\n",
    "<br>\n",
    "\n",
    "The theories of linear time series discussed include:\n",
    "\n",
    "- stationarity\n",
    "\n",
    "- dynamic dependence\n",
    "\n",
    "- autocorrelation function\n",
    "\n",
    "- modeling\n",
    "\n",
    "- forecasting\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "The econometric models introduced include: \n",
    "\n",
    "- (a) simple autoregressive (AR) models\n",
    "\n",
    "- (b) simple moving-average (MA) models\n",
    "\n",
    "- (c) mixed autoregressive moving-average (ARMA) models\n",
    "\n",
    "- (d) unit-root nonstationarity\n",
    "\n",
    "- (e) regression models with times series errors\n",
    "\n",
    "- (f) fractionally differenced models for long-range dependence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1 Stationarity\n",
    "\n",
    "The foundation of time series analysis is stationarity. A time series $\\{r_{t}\\}$ is said to be _strictly stationary_ if the joint distribution of\n",
    "$(r_{t_{1} + t}, \\ldots, r_{t_{k} + t})$ for all $t$, where $k$ is an arbitrary positive integer and $(t_{1}, \\ldots, t_{k})$ is a collection of $k$ positive integers. \n",
    "\n",
    "<br>\n",
    "\n",
    "Strict stationarity requires that the joint distribution of $(r_{t_{1} + t}, \\ldots, r_{t_{k} + t})$ is invariant under time shift. This is a very strong requirement that is challenging to verify empirically. For this reason, we often employ a simpler form of stationarity. \n",
    "\n",
    "<br>\n",
    "\n",
    "A time series is $\\{r_{t}\\}$ _weakly stationary_ if both the mean of $r_{t}$ and the covariance between $r_{t}$ and $r_{t-l}$ are time invariant, where $l$ is an arbitrary integer.\n",
    "\n",
    "<br>\n",
    "\n",
    "More specifically, $\\{r_{t}\\}$ is weakly stationary if:\n",
    "\n",
    "- (a) $E(r_{t}) = \\mu$, which is constant\n",
    "\n",
    "- (b) $Cov(r_{t}, r_{t-l}) = \\gamma_{l}$, which only depends on $l$\n",
    "\n",
    "<br>\n",
    "\n",
    "In practice, suppose that we have observed $T$ data points $\\{r_{t} | 1, \\ldots, T\\}$. Weak stationarity implies that a time plot of the data would show that the $T$ values fluctuate with constant variation around a fixed level. In application, weak stationarity enables one to make inference concerning future observations (e.g. prediction).\n",
    "\n",
    "<br>\n",
    "\n",
    "Implicitly, in the condition of weak stationarity, we assume that the first two moments of $r_{t}$ are finite. From the definitions, if $r_{t}$ is strictly stationary and its first two moments are finite, then $r_{t}$ is also weakly stationary. The converse is not true in general. \n",
    "\n",
    "<br>\n",
    "\n",
    "If the time series $r_{t}$ is normally distributed, then weak stationarity is equivalent to strict stationarity. \n",
    "\n",
    "<br>\n",
    "\n",
    "We will be mainly concerned with weakly stationary time series.\n",
    "\n",
    "<br>\n",
    "\n",
    "The covariance $\\gamma_{l} = Cov(r_{t}, r_{t-1})$ is called the lag-$l$ autocovariance of $r_{t}$. It has two important properties: \n",
    "\n",
    "- (a) $\\gamma_{0} = Var(r_{t})$\n",
    "\n",
    "- (b) $\\gamma_{-l} = \\gamma_{l}$\n",
    "\n",
    "The second property holds because $Cov(r_{t}, r_{t-(-l)}) = Cov(r_{t-(-l)}, r_{t}) = Cov(r_{t+l}, r_{t}) = Cov(r_{t_{1}}, r_{t_{1} - l})$, where $t_{1} = t + l$. \n",
    "\n",
    "<br>\n",
    "\n",
    "In the finance literature, is common to assume that an asset return series is weakly stationary. We can check this empirically given a sufficient number of historical returns observations. In particular, we can divide the historical returns into subsamples and check the consistency of the results obtained across subsamples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.2 Correlation and Autocorrelation Function\n",
    "\n",
    "Recall that the correlation between two random variables $X$ and $Y$ can be defined as:\n",
    "\n",
    "$$\n",
    "\\rho_{x,y} = \\frac{Cov(X,Y)}{\\sqrt{Var(X) Var(Y)}} = \\frac{E[(X - \\mu_{x}) (Y - \\mu_{y})]}{\\sqrt{E[(X - \\mu_{x})^{2}] E[(Y - \\mu_{y})^{2}]}}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "This coefficient measures the strength between $X$ and $Y$, and can be shown that $-1 \\le \\rho_{x,y} \\le +1$, and that $\\rho_{x,y} = \\rho{y,x}$. The two random variables are uncorrelated if $\\rho_{x,y} = 0$. In addition, if both $X$ and $Y$ are normally distributed random variables then the condition that $\\rho_{x,y} = 0$ also indicates that they are independent. \n",
    "\n",
    "<br>\n",
    "\n",
    "When the sample $\\{(x_{t}, y_{t})\\}_{t=1}^{T}$ then the population parameter can be estimated by its sample counterpart: \n",
    "\n",
    "$$\n",
    "\\hat{\\rho}_{x,y} = \\frac{\\sum_{t=1}^{T} (x_{t} - \\tilde{x}) (y_{t} - \\tilde{y})}{\\sqrt{\\sum_{t=1}^{T} (x_{t} - \\tilde{x})^{2}) \\sum_{t=1}^{T} (y_{t} - \\tilde{y})^{2}}}\n",
    "$$\n",
    "\n",
    "where $\\tilde{x} = \\frac{1}{T}\\sum_{t=1}^{T} x_{t}$ and $\\tilde{y} = \\frac{1}{T}\\sum_{t=1}^{T} y_{t}$ are the sample mean of $X$ and $Y$, respectively. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.3 White Noise and Linear Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.4 Simple AR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of AR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying AR Models in Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness of Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.5 Simple MA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of MA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying MA Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting Using MA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.6 Simple ARMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of ARMA(1,1) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General ARMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying ARMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting Using an ARMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three Model Representations for an ARMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.7 Unit-Root Nonstationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk with Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend-Stationary Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Unit-Root Nonstationary Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit-Root Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.8 Seasonal Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Differencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicative Seasonal Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.9 Regression Models with Time Series Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.10 Consistent Covariance Matrix Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.11 Long-Memory Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
